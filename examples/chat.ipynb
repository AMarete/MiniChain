{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660ed9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:43.874984Z",
     "iopub.status.busy": "2023-03-23T15:19:43.874008Z",
     "iopub.status.idle": "2023-03-23T15:19:43.897184Z",
     "shell.execute_reply": "2023-03-23T15:19:43.895124Z"
    },
    "lines_to_next_cell": 2,
    "tags": [
     "hide_inp"
    ]
   },
   "outputs": [],
   "source": [
    "desc = \"\"\"\n",
    "### Chat\n",
    "\n",
    "A chat-like example for multi-turn chat with state. [[Code](https://github.com/srush/MiniChain/blob/main/examples/chat.py)]\n",
    "\n",
    "(Adapted from [LangChain](https://langchain.readthedocs.io/en/latest/modules/memory/examples/chatgpt_clone.html)'s version of this [blog post](https://www.engraved.blog/building-a-virtual-machine-inside/).)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c647c",
   "metadata": {},
   "source": [
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50809efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:43.905356Z",
     "iopub.status.busy": "2023-03-23T15:19:43.904904Z",
     "iopub.status.idle": "2023-03-23T15:19:45.193851Z",
     "shell.execute_reply": "2023-03-23T15:19:45.193235Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, replace\n",
    "from typing import List, Tuple\n",
    "from minichain import OpenAI, prompt, show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db7a7a",
   "metadata": {},
   "source": [
    "Generic stateful Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3f8afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:45.196775Z",
     "iopub.status.busy": "2023-03-23T15:19:45.196330Z",
     "iopub.status.idle": "2023-03-23T15:19:45.199549Z",
     "shell.execute_reply": "2023-03-23T15:19:45.198961Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "MEMORY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fddf9e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:45.202267Z",
     "iopub.status.busy": "2023-03-23T15:19:45.201663Z",
     "iopub.status.idle": "2023-03-23T15:19:45.206094Z",
     "shell.execute_reply": "2023-03-23T15:19:45.205492Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    memory: List[Tuple[str, str]]\n",
    "    human_input: str = \"\"\n",
    "\n",
    "    def push(self, response: str) -> \"State\":\n",
    "        memory = self.memory if len(self.memory) < MEMORY else self.memory[1:]\n",
    "        return State(memory + [(self.human_input, response)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae61707",
   "metadata": {},
   "source": [
    "Chat prompt with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03d3175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:45.208393Z",
     "iopub.status.busy": "2023-03-23T15:19:45.208210Z",
     "iopub.status.idle": "2023-03-23T15:19:45.211519Z",
     "shell.execute_reply": "2023-03-23T15:19:45.211089Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@prompt(OpenAI(), template_file=\"chat.pmpt.tpl\")\n",
    "def chat_prompt(model, state: State) -> State:\n",
    "    out = model(state)\n",
    "    result = out.split(\"Assistant:\")[-1]\n",
    "    return state.push(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6520d31",
   "metadata": {},
   "source": [
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4a2f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:45.213881Z",
     "iopub.status.busy": "2023-03-23T15:19:45.213394Z",
     "iopub.status.idle": "2023-03-23T15:19:45.216282Z",
     "shell.execute_reply": "2023-03-23T15:19:45.215872Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"ls ~\",\n",
    "    \"cd ~\",\n",
    "    \"{Please make a file jokes.txt inside and put some jokes inside}\",\n",
    "    \"\"\"echo -e \"x=lambda y:y*5+3;print('Result:' + str(x(6)))\" > run.py && python3 run.py\"\"\",\n",
    "    \"\"\"echo -e \"print(list(filter(lambda x: all(x%d for d in range(2,x)),range(2,3**10)))[:10])\" > run.py && python3 run.py\"\"\",\n",
    "    \"\"\"echo -e \"echo 'Hello from Docker\" > entrypoint.sh && echo -e \"FROM ubuntu:20.04\\nCOPY entrypoint.sh entrypoint.sh\\nENTRYPOINT [\\\"/bin/sh\\\",\\\"entrypoint.sh\\\"]\">Dockerfile && docker build . -t my_docker_image && docker run -t my_docker_image\"\"\",\n",
    "    \"nvidia-smi\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a988f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T15:19:45.218440Z",
     "iopub.status.busy": "2023-03-23T15:19:45.218071Z",
     "iopub.status.idle": "2023-03-23T15:19:45.547577Z",
     "shell.execute_reply": "2023-03-23T15:19:45.546942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradio = show(lambda command, state: chat_prompt(replace(state, human_input=command)),\n",
    "              initial_state=State([]),\n",
    "              subprompts=[chat_prompt],\n",
    "              examples=examples,\n",
    "              out_type=\"json\",\n",
    "              description=desc,\n",
    "              code=open(\"chat.py\", \"r\").read().split(\"$\")[1].strip().strip(\"#\").strip(),\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    gradio.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c588ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "minichain",
   "language": "python",
   "name": "minichain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
